---
title: "CITY_US_new"
output:
    html_document:
        # df_print: paged
        toc: true
        toc_float: true 
---


```{r, include=FALSE}
knitr::opts_chunk$set(fig.width = 8, fig.height = 8)
# knitr::opts_chunk$set(
#     # This should allow Rmarkdown to locate the data
#     root.dir = rprojroot::find_rstudio_root_file()
# )
library(readxl)
library(reshape2)
library(ggplot2)
library(GGally)
library(stringr)
library(correlation) # cor_sort
library(forcats)
library(tidyr)
library(symmetry)
library(moments)
library(qqplotr)
library(nortest)
library(entropy)
library(car)
library(ppcor)
library(dplyr)
library(lm.beta)
library(olsrr)
library(mvtnorm)
```

# 1 Предварительный анализ данных

```{r}
if (interactive() && !str_ends(getwd(), "R/stat_anal/CITY_US")) {
    setwd("R/stat_anal/CITY_US")
}

data <- read_excel("CITY_shortname.xls")
data[data == "NA"] <- NA
data[, -(1:2)] <- data.frame(lapply(data[, -(1:2)], as.numeric))
fullnames <- names(read_excel("CITY.xls"))
```

## 1.1 Разобраться в том, что означают признаки.

```{r}
print(fullnames)
```

## 1.2 Отобрать признаки

```{r}
names_interesting <- c("AREA", "POP80", "POP92", "POPDEN", "CRIME", "BORN_F", "POVERT", "INCOME", "UNEMP", "TEMPER")

data <- data %>% select(all_of(c("CITY", "STATE", names_interesting)))

print(head(data))
```

## 1.3 Определить вид признаков

Город и штат качественные, остальные количественные, ранги были порядковыми.


```{r}
find_mode_freq <- function(x) {
    x <- x[!is.na(x)]
    return(max(tabulate(match(x, x))))
}

print(data %>% summarise(across(
    all_of(names_interesting),
    find_mode_freq
)))

print(sort(data$UNEMP))
```

Все количественные буду считать непрерывными.
возможно UNEMP непрерывный с плохой точностью.

## 1.4 не актуально

## 1.5 Построить matrix plot

```{r, message=FALSE, warning=FALSE}
# if (interactive()) pdf("ggpairs_unedited.pdf")
# ggpairs(
#     data[, -(1:2)],
#     lower = list(continuous = wrap("points", alpha = 0.5, size = 0.3)),
#     diag = list(continuous = "barDiag")
# )
# if (interactive()) dev.off()
```

## 1.7 outliers

Убираю outliers:

Помечаю некорректные данные в INCOME как NA.
Удаляю город из Аляски за плотность населения.
Флорида выделсется на BORN_F-INCOME
Гаваи выделяются низким уровнем безработицы. странно?

```{r}
data$INCOME[data$INCOME < 100] <- NA
data <- data %>% filter(STATE != "AK")
```

## 1.6 Несимметричные распределения

Функция, которая логарифмирует, если это сделает выборку симметричнее

```{r}
log_asymmetric <- function(x) {
    if (skewness(x, na.rm = TRUE) < abs(skewness(log(x), na.rm = TRUE))) {
        print("default")
        return(x)
    } else {
        print("logged")
        return(log(x))
    }
}
```

Автоматически логарифмирую то что имеет асимметрию  и длинный хвост справа

```{r}
data_logged <- data %>%
    mutate(across(all_of(names_interesting), log_asymmetric))
```

```{r, message=FALSE, warning=FALSE}
# if (interactive()) pdf("ggpairs_logged.pdf")
# ggpairs(
#     data_logged[, -(1:2)],
#     lower = list(continuous = wrap("points", alpha = 0.5, size = 0.3)),
#     diag = list(continuous = "barDiag")
# )
# if (interactive()) dev.off()
```

## 1.8 однородность

выглядит однородно.


## .9 не актуально

## 1.10 всякие характеристики

```{r}
print_characteristics <- function(x) {
    list(
        mean = mean(x, na.rm = TRUE),
        var = var(x, na.rm = TRUE),
        skewness = skewness(x, na.rm = TRUE),
        kurtosis = kurtosis(x, na.rm = TRUE) - 3
    )
}

sapply(data_logged %>% select(all_of
(names_interesting)), print_characteristics)
```


```{r}
df <- data_logged %>%
    select(-CITY, -STATE) %>%
    drop_na()

ggplot(melt(cor(df))) +
    geom_raster(aes(x = Var2, y = Var1, fill = value)) +
    geom_text(aes(x = Var2, y = Var1, label = round(value, 2))) +
    scale_fill_gradient2() +
    theme_dark() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

# 2 Задаете зависимые и 'независимые' переменные (регрессоры), не забываете обратить внимание на выбор способа обработки пропущенных наблюдений, функция lm.

```{r}
df <- data_logged %>%
    select(-CITY, -STATE, -POP92, -POVERT, -POPDEN) %>%
    drop_na()

model <- lm.beta(lm(CRIME ~ ., data = df, na.action = na.exclude))
# model.beta <- lm.beta(model)
# summary(model)
summary(model)


ggplot(melt(cov2cor(vcov(model)))) +
    geom_raster(aes(x = Var2, y = Var1, fill = value)) +
    geom_text(aes(x = Var2, y = Var1, label = round(value, 2))) +
    scale_fill_gradient2() +
    theme_dark() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

# cov2cor(vcov(model))
```

# 3 Интерпретируете результаты регрессии, включая результат lm.beta (в частности, о разнице между b и beta, о значимости и пр.).





# 4 Далее есть три проблемы, из-за которых результаты регрессии могут быть неправильными

## линейная модель регрессии не соответствует даннымв данных
    жаль
## могут быть сильно зависимые «независимые» переменные
    есть население в 80 и 92
## также могут быть outliers.
    outliers уже убраны, если какие-то и остались, это не так критично
    

# 5 Как строятся доверительные интервалы и двумерные доверительные области. 
На примере пары признаков строите двумерный доверительный интервал для пары значащих коэффициентов регрессии, интерпретируете: (1) оба признака влияют на результат согласно оценкам коэффициентов регрессии перед ними: или (2) признаки вместе сильно влияют, но не различить, какой из них больше; или (3) непонятно, или оба признака слабо влияют, или оба влияют сильно. 

```{r}
# df <- data_logged %>% select(-CITY, -STATE)

# model2 <- lm.beta(lm(CRIME ~ POVERT + UNEMP, data = df, na.action = na.exclude))
# # summary(model)
# summary(model2)


# cov_matrix <- vcov(model2)
# # cor_matrix <- cov2cor(vcov(model2))

# ggplot(melt(cov2cor(cov_matrix))) +
#     geom_raster(aes(x = Var2, y = Var1, fill = value)) +
#     geom_text(aes(x = Var2, y = Var1, label = round(value, 2))) +
#     scale_fill_gradient2() +
#     theme_dark() +
#     theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

# cov2cor(vcov(model))
```


```{r}
plot_ellipse <- function(model_, id) {
    # model_ <- model

    mean <- model_$standardized.coefficients[id]

    sd <- cov2cor(vcov(model_))[id, id]

    # id <- c(3, 6)

    net <- expand.grid(list(
        x = seq(mean[1] - 3, mean[1] + 3, by = .1),
        y = seq(mean[2] - 3, mean[2] + 3, by = .1)
    )) %>%
        mutate(
            z = dmvnorm(cbind(x, y), mean, sd)
        )

    ggplot() +
        # geom_point(data = ring, aes(x = x, y = y)) +
        geom_point(data = data.frame(x = 0, y = 0), aes(x = x, y = y), size = 5) +
        geom_contour(data = net, aes(x = x, y = y, z = z))

    # plot()
}
```


```{r}
plot_ellipse(model, c(3, 6))
plot_ellipse(model, c(3, 7))
# plot_ellipse(model, c(3, 8))
# plot_ellipse(model, c(3, 9))
# plot_ellipse(model, c(3, 10))
plot_ellipse(model, c(4, 5))
plot_ellipse(model, c(6, 7))
```

```{r}
confidenceEllipse(lm.beta(lm(CRIME ~ INCOME + UNEMP, data = df)))
```